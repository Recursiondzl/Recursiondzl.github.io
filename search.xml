<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>LSTR论文解析</title>
    <url>/2022/03/04/LSTR%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<blockquote>
<p>论文链接：<a href="https://arxiv.org/pdf/2011.04233.pdf">https://arxiv.org/pdf/2011.04233.pdf</a><br>论文出处：WACV2020<br>论文代码：<a href="https://github.com/liuruijin17/LSTR">https://github.com/liuruijin17/LSTR</a></p>
</blockquote>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><p><strong>车道线检测是将车道识别为近似曲线的过程。</strong></p>
</li>
<li><p><strong>主流的pipeline是分成2步解决问题：特征提取和后处理。虽然有用，但效率低下。</strong></p>
</li>
<li><p><strong>本文提出了一种端到端方法，该方法可以直接输出车道形状模型的参数</strong>，使用通过transformer构建的网络来学习更丰富的结构和上下文。</p>
</li>
<li><p>车道形状模型是基于道路结构和摄像头姿势制定的，可为网络输出的参数提供物理解释。</p>
</li>
<li><p>transformer使用自我注意机制（self-attention mechanism）对非局部交互进行建模，以捕获细长的结构和全局上下文。</p>
</li>
<li><p>该方法已在TuSimple基准测试中得到验证，并以最轻巧的模型尺寸和最快的速度显示了最新的准确性。</p>
</li>
</ul>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h1><ul>
<li><p><strong>车道检测实际应用中challenges：（1）车道标线是一个细长的结构，外观线索很少（2）车道标记类型不同、光线变化以及车辆和行人的遮挡（3）算法的高运行效率和传输适应性对于在移动设备上部署</strong></p>
</li>
<li><p><strong>早期方法：先分割车道线，再做聚合（segment clustering），再做曲线拟合。</strong></p>
</li>
<li><p><strong>一些方法使用消息传递或额外的场景注释来捕获全局上下文，以提高最终性能，但这些方法不可避免地会消耗更多的时间和数据成本。</strong></p>
</li>
<li><p><strong>缺点：这些方法效率低，且做车道线分割时忽略全局上下文信息（global context）</strong></p>
</li>
<li><p>为了解决效率和车道线结构的问题，建议将<strong>车道检测输出重构为车道形状模型的参数</strong>（parameters of a lane shape model），并开发一个<strong>由非局部构件（non-local building blocks）</strong>构建的网络，<strong>以加强对全局上下文信息和车道细长结构的学习。</strong></p>
</li>
<li><p><strong>每个车道的输出是一组参数</strong>，这些参数通过从道路结构和摄像机姿态推导出的显式<strong>数学公式近似于车道标记</strong>。在给定摄像机固有参数等特定先验条件下，无需任何3D传感器，<strong>这些参数就可以用于计算道路曲率和摄像机俯仰角。</strong></p>
</li>
<li><p>开发了一个<strong>基于transformer的网络</strong>，该网络从任何成对的视觉特征中总结信息，使其能够捕获车道线的狭长结构和全局上下文信息（ global context）。<br><strong>整个体系结构立即预测输出</strong>，并<strong>采用匈牙利损失（Hungarian loss）进行端到端训练</strong>。<br>损失模型采用预测与真值之间的双边匹配（ bipartite matching），保证一对一的无序分配，<strong>使模型消除了显性的非极大抑制过程。</strong></p>
</li>
<li><p>在常规的多车道检测基准TuSimple上验证了该方法的有效性。</p>
</li>
<li><p>为了评估对新场景的适应性，我们在多个城市收集了大量具有挑战性的数据集，称为前视车道(FVL)，跨越各种场景(城市和高速公路、白天和夜晚、各种交通和天气条件)。该方法在复杂数据集不包含夜景等场景的情况下，对新场景具有较强的适应性。</p>
</li>
<li><p>本文主要贡献：<br>（1）<strong>提出了一种车道形状模型，其参数作为直接回归输出，反映道路结构和摄像机姿态。</strong><br>（2）开发了一个<strong>基于transformer的网络</strong>，该网络考虑了非局部的相互作用，<strong>以捕获车道和全局上下文的细长结构。</strong><br>（3）<strong>本文方法以最少的资源消耗达到了最先进的精度，并对具有挑战性的自采集车道检测数据集显示了良好的适应性。</strong></p>
</li>
</ul>
<h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><p>  <del>参数有现实意义</del></p>
<h1 id="3-Method"><a href="#3-Method" class="headerlink" title="3.Method"></a>3.Method</h1><p><strong>本文端到端方法重构输出为车道形状模型的参数。通过基于transformer的网络with匈牙利拟合损失对参数进行预测。</strong></p>
<h2 id="3-1车道形状模型（Lane-Shape-Model）"><a href="#3-1车道形状模型（Lane-Shape-Model）" class="headerlink" title="3.1车道形状模型（Lane Shape Model）"></a>3.1车道形状模型（Lane Shape Model）</h2><ul>
<li>车道形状的先验模型被定义为多项式。通常，<strong>三次曲线</strong>用来近似平地上的单车道线：(1)<br>其中k，m，n，b是实数参数，(X，Z)表示地平面的点。</li>
<li>当光轴平行于地平面时，从道路屏幕投影到图像平面的曲线为：(2)</li>
<li>对于一个倾斜相机的光轴与地平面成φ角时，从不倾斜的图像平面到倾斜的图像平面的曲线转换为：(3)</li>
<li>其中 f 是焦距，(u’， v’)是倾角转换的点位置，当 φ = 0，公式（3）简化成公式（2）。</li>
</ul>
<p>曲线的重新参数化</p>
<p>此外，还引入了垂直起止偏移量α、β来参数化各车道线。这两个参数提供了基本的定位信息来描述车道线的上下边界。</p>
<ul>
<li>在真实的道路条件下，车道通常具有全局一致的形状。因此，近似圆弧从左到右车道的曲率相等，因此k′′,f′′,m′′,n′将被所有车道共享。因此，t-th车道的输出被重新参数化为gt：(5)<br>其中 t∈{1,…,T}，T 是图像中车道线的数量，每个车道仅在偏差项和上下边界上有所不同。</li>
</ul>
<h2 id="3-2-匈牙利拟合损失（Hungarian-Fitting-Loss）"><a href="#3-2-匈牙利拟合损失（Hungarian-Fitting-Loss）" class="headerlink" title="3.2 匈牙利拟合损失（Hungarian Fitting Loss）"></a>3.2 匈牙利拟合损失（Hungarian Fitting Loss）</h2><ul>
<li>匈牙利拟合损失在预测参数和车道真值之间进行匹配，采用匈牙利算法有效地解决了匹配问题，然后利用匹配结果优化路径相关回归损失。</li>
<li>损失模型采用预测与真值之间的双边匹配（ bipartite matching）。</li>
</ul>
<h2 id="3-3-网络结构"><a href="#3-3-网络结构" class="headerlink" title="3.3 网络结构"></a>3.3 网络结构</h2><p><strong>一个主干（backbone）、一个简化transformer网络、几个用于参数预测的前馈网络(FFNs)和匈牙利损失。</strong><br><img src="/2022/03/04/LSTR%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/2022-03-04-20-06-32.png" alt></p>
<ul>
<li>给定输入图像 I，主干提取低分辨率特征，然后通过压缩空间维度将其压缩成一个序列 S。S和位置嵌入 Ep 馈入transformer， Encoder以输出表示序列 Se。</li>
<li>然后，Decoder首先处理一个初始查询序列 Sq 和一个隐式学习位置差异的学习位置嵌入 ELL 生成输出序列 Sd，计算与 Se 和 Ep 的交互以处理相关特征。</li>
<li><p>最后，有几种FFNs直接对所提出的输出参数进行预测。</p>
</li>
<li><p>主干是建立在reduced ResNet18的基础上。原ResNet18有4个block和16倍下采样功能。每个块的输出通道为“64、128、256、512”。</p>
</li>
<li>本文简化 ResNet18将输出通道削减为“16、32、64、128”以避免过拟合，并将降采样因子设置为8以减少车道结构细节的损失。</li>
<li>Backbone利用输入图像作为输入，提取低分辨率特征，对高分辨率车道空间表示进行编码。</li>
<li>接下来，为了构造一个作为编码器输入的序列，将该特征在空间维度上进行平铺，得到一个长度为HW×C的序列S，其中HW表示序列的长度，C为信道数。</li>
</ul>
<h2 id="3-4Encoder"><a href="#3-4Encoder" class="headerlink" title="3.4Encoder"></a>3.4Encoder</h2><p>编码器有两个按顺序链接的标准层。它们分别由一个自注意模块和一个前馈层组成，如图2所示。<br>在抽象空间表示序列S的基础上，利用基于绝对位置的正体嵌入Ep对位置信息进行编码，以避免排列变化。该Ep具有与s相同的尺寸。编码器通过下式执行缩放点积注意（scaled dot-product attention）：<br>其中Q,K,V表示对每个输入行进行线性变换的查询、键和值序列，A表示度量非局部交互以捕获纤细结构和全局上下文的注意力映射，O表示自注意的输出。<br>HW×C形状的编码器Se的输出序列是通过FNNs、层归一化的residual连接和另一个相同的编码器层得到的。</p>
<h2 id="3-5-Decoder"><a href="#3-5-Decoder" class="headerlink" title="3.5 Decoder"></a>3.5 Decoder</h2><p>解码器也有两个标准层。与编码器不同的是，每一层都插入另一个注意模块，该模块期望编码器的输出，使编码器能够对包含空间信息的特征执行注意机制，从而与最相关的特征元素相关联。<br>面对翻译任务，原转换器将地真序列移位一个位置，作为译码器的输入，使其每次并行输出序列中的每个元素。<br>在车道检测任务中，我们将输入的Sq设置为一个空的N×C矩阵，并直接一次解码所有的曲线参数。<br>此外，我们引入了一种N×C的学习车道嵌入算法，作为隐式学习全局车道信息的位置嵌入。注意机制与公式9相同，解码后的N×C形状的序列Sd与编码方法相似。<br>训练时，在每一解码层之后进行中间监督。</p>
<p>FFNs用于预测曲线参数<br>预测模块通过三部分生成预测曲线H集合。单个线性操作直接将Sd投射为N×2，然后softmax层对其进行最后维运算，得到预测标签(background或lane)ci.<br>同时，一个具有ReLU激活和隐C维的3层感知器将Sd投射为N×4，其中维4表示四组特定路径参数。另一个3层感知器首先将一个特征投影到N×4，然后在第一维取平均值，得到4个共享参数。</p>
<h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h1><p>针对形状模型的对比</p>
<p>编码器层数的对比（Number of encoder layers）</p>
<p>解码器层数的对比（Number of decoder layers）</p>
<p>预测曲线数量的对比（Number of predicted curves）、</p>
<h2 id="4-1FVL-Dataset上的迁移测试"><a href="#4-1FVL-Dataset上的迁移测试" class="headerlink" title="4.1FVL Dataset上的迁移测试"></a>4.1FVL Dataset上的迁移测试</h2><p>并没有在FVL数据集上训练。</p>
<h1 id="5-结论"><a href="#5-结论" class="headerlink" title="5.结论"></a>5.结论</h1><p>Future work：<br>（1）研究复杂、细微的车道线检测任务；<br>（2）引入跟踪功能。</p>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown教程</title>
    <url>/2022/03/03/Markdown%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p><meta name="referrer" content="no-referrer"></p>
<h1 id="‘-’表示标题"><a href="#‘-’表示标题" class="headerlink" title="‘#’表示标题"></a>‘#’表示标题</h1><h2 id="‘-’表示二级标题"><a href="#‘-’表示二级标题" class="headerlink" title="‘##’表示二级标题"></a>‘##’表示二级标题</h2><pre><code>正文直接写

加粗前后用**或者control+B
**强调**

用一个*变斜或者control+I
*变斜*

1. 有序列表1.+空格
   1. tab添加二级列表
2. 二级列表

插入图片：
1. 复制图片
2. control+Alt+v
*orz*
</code></pre><h3 id="‘-’表示三级标题"><a href="#‘-’表示三级标题" class="headerlink" title="‘###’表示三级标题"></a>‘###’表示三级标题</h3><pre><code>&quot;$$&quot;中间可以用Latex&quot;$$&quot;
</code></pre><script type="math/tex; mode=display">
\lim_{x \to \infin}\frac{sin(t)}{x}=1</script><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th style="text-align:center">2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>control+c<br>contron+v<br><a href="https://recursiondzl.github.io/">https://recursiondzl.github.io/</a></p>
<h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><p><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-07-34.png" alt><br><figure class="highlight cpp"><table><tr><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    cout&lt;&lt;<span class="hljs-string">&quot;Hello&quot;</span>&lt;&lt;endl;<br>&#125;<br></code></pre></td></tr></table></figure></p>
<h2 id="视频教程"><a href="#视频教程" class="headerlink" title="视频教程"></a>视频教程</h2><p><a href="https://www.bilibili.com/video/BV1si4y1472o">https://www.bilibili.com/video/BV1si4y1472o</a></p>
<h2 id="关于图片不显示的问题："><a href="#关于图片不显示的问题：" class="headerlink" title="关于图片不显示的问题："></a>关于图片不显示的问题：</h2><p><a href="https://www.bilibili.com/video/BV1D7411U7Yk?from=search&amp;seid=11253000681586254379&amp;spm_id_from=333.337.0.0">https://www.bilibili.com/video/BV1D7411U7Yk?from=search&amp;seid=11253000681586254379&amp;spm_id_from=333.337.0.0</a></p>
<p><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-11-03-04.png" alt></p>
<hr>
<h1 id="2022-3-4-Version-2-0"><a href="#2022-3-4-Version-2-0" class="headerlink" title="2022.3.4 Version 2.0"></a>2022.3.4 Version 2.0</h1><h2 id="1-快捷键"><a href="#1-快捷键" class="headerlink" title="1.快捷键"></a>1.快捷键</h2><p>功能        快捷键<br>加粗        Ctrl + B<br>斜体        Ctrl + I<br>引用        Ctrl + Q<br>插入链接    Ctrl + L<br>插入代码    Ctrl + K<br>插入图片    Ctrl + G<br>提升标题    Ctrl + H<br>有序列表    Ctrl + O<br>无序列表    Ctrl + U<br>横线        Ctrl + R<br>撤销        Ctrl + Z<br>重做        Ctrl + Y</p>
<h2 id="2-字体设置斜体、粗体、删除线"><a href="#2-字体设置斜体、粗体、删除线" class="headerlink" title="2.字体设置斜体、粗体、删除线"></a>2.字体设置斜体、粗体、删除线</h2><p><em>这里是文字</em><br><em>这里是文字</em><br><strong>这里是文字</strong><br><strong><em>这里是文字</em></strong><br><del>这里是文字</del><br><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-05-28.png" alt></p>
<h2 id="3-分割线"><a href="#3-分割线" class="headerlink" title="3.分割线"></a>3.分割线</h2><p>你可以在一行中用三个以上的星号(*)、减号(-)、底线(_)来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。</p>
<h2 id="4-引用"><a href="#4-引用" class="headerlink" title="4.引用"></a>4.引用</h2><p>在被引用的文本前加上&gt;符号，以及一个空格就可以了，如果只输入了一个&gt;符号会产生一个空白的引用。</p>
<blockquote>
<p>好耶</p>
</blockquote>
<h2 id="5-引用的嵌套使用"><a href="#5-引用的嵌套使用" class="headerlink" title="5.引用的嵌套使用"></a>5.引用的嵌套使用</h2><p><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-09-51.png" alt></p>
<p><del>看教程看到一半发现有更好的教程，上面也懒得删了</del></p>
<p><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-28-22.png" alt><br><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-28-56.png" alt><br><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-29-33.png" alt><br><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-29-58.png" alt><br><img src="/2022/03/03/Markdown%E6%95%99%E7%A8%8B/2022-03-04-16-30-16.png" alt></p>
]]></content>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/03/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Transform解析</title>
    <url>/2022/03/04/Transform%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h1 id="Attention详解"><a href="#Attention详解" class="headerlink" title="Attention详解"></a>Attention详解</h1><h2 id="1-Encoder-Decoder"><a href="#1-Encoder-Decoder" class="headerlink" title="1.Encoder-Decoder"></a>1.Encoder-Decoder</h2><p>在NLP中Encoder-Decoder框架主要被用来处理序列-序列问题。也就是输入一个序列，生成一个序列的问题。这两个序列可以分别是任意长度。具体到NLP中的任务比如：<br>    文本摘要，输入一篇文章(序列数据)，生成文章的摘要(序列数据)<br>    文本翻译，输入一句或一篇英文(序列数据)，生成翻译后的中文(序列数据)<br>    问答系统，输入一个question（序列数据），生成一个answer（序列数据）</p>
<h2 id="2-Encoder-Decoder结构原理"><a href="#2-Encoder-Decoder结构原理" class="headerlink" title="2.Encoder-Decoder结构原理"></a>2.Encoder-Decoder结构原理</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-09-48.png" alt></p>
<h1 id="Transformer-原理"><a href="#Transformer-原理" class="headerlink" title="Transformer 原理"></a>Transformer 原理</h1><h2 id="1-Transformer整体结构"><a href="#1-Transformer整体结构" class="headerlink" title="1.Transformer整体结构"></a>1.Transformer整体结构</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-14-17.png" alt></p>
<p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-15-32.png" alt></p>
<h2 id="2-Transformer的Encoder"><a href="#2-Transformer的Encoder" class="headerlink" title="2.Transformer的Encoder"></a>2.Transformer的Encoder</h2><p>  Encoder block是由6个encoder堆叠而成，Nx=6。从图中我们可以看出一个encoder由Multi-Head Attention 和 全连接神经网络Feed Forward Network构成。</p>
<p>  <img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-21-00.png" alt><br>  <img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-21-59.png" alt><br>  <img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-22-33.png" alt></p>
<h1 id="视频讲解"><a href="#视频讲解" class="headerlink" title="视频讲解"></a>视频讲解</h1><p>  <a href="https://www.bilibili.com/video/BV1Di4y1c7Zm?from=search&amp;seid=2664793220430108654&amp;spm_id_from=333.337.0.0">https://www.bilibili.com/video/BV1Di4y1c7Zm?from=search&amp;seid=2664793220430108654&amp;spm_id_from=333.337.0.0</a></p>
<p>  <img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-26-28.png" alt></p>
<h2 id="1-内部结构"><a href="#1-内部结构" class="headerlink" title="1.内部结构"></a>1.内部结构</h2><p>  <img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-27-29.png" alt></p>
<p><strong>六个Encoder结构相同但参数不同，Decode也是一样的道理</strong></p>
<h2 id="3-位置编码"><a href="#3-位置编码" class="headerlink" title="3.位置编码"></a>3.位置编码</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-35-56.png" alt><br>  2i位置用sin,2i+1位置用cos</p>
<p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-39-12.png" alt><br>   位置相加<br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-40-21.png" alt> </p>
<h2 id="4-注意力机制"><a href="#4-注意力机制" class="headerlink" title="4.注意力机制"></a>4.注意力机制</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-43-59.png" alt><br>  Q K V为三个矩阵<br>  归一化后乘以V矩阵</p>
<p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-45-57.png" alt><br>  Query 和 Key 点乘(反应向量相似度，结果越大越相似)<br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-49-20.png" alt></p>
<h3 id="4-1如何获取QKV"><a href="#4-1如何获取QKV" class="headerlink" title="4.1如何获取QKV"></a>4.1如何获取QKV</h3><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-51-23.png" alt><br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-53-25.png" alt><br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-54-32.png" alt></p>
<p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-55-22.png" alt><br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-56-59.png" alt><br>多头注意力机制，使用多套WQ WK WV矩阵，最后合在一起输出</p>
<h2 id="5-残差"><a href="#5-残差" class="headerlink" title="5.残差"></a>5.残差</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-14-59-13.png" alt><br><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-15-01-27.png" alt></p>
<h2 id="6-Layernormal"><a href="#6-Layernormal" class="headerlink" title="6.Layernormal"></a>6.Layernormal</h2><pre><code>BN与LN的区别在于：
</code></pre><p>  LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；<br>  BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。<br>  所以，LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<h2 id="7-Feed-Forward"><a href="#7-Feed-Forward" class="headerlink" title="7.Feed-Forward"></a>7.Feed-Forward</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-15-08-50.png" alt></p>
<h2 id="8-Decoder"><a href="#8-Decoder" class="headerlink" title="8.Decoder"></a>8.Decoder</h2><p><img src="/2022/03/04/Transform%E8%A7%A3%E6%9E%90/2022-03-04-15-15-45.png" alt><br>生成Q矩阵</p>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo使用教程</title>
    <url>/2022/03/03/hexo%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>1.hexo n “title” 新建一个文章</p>
<p>2.hexo g 重新生成博客</p>
<p>3.hexo s 本地运行</p>
<p>4.hexo clean 清除缓存</p>
<p>5.hexo d 上传到github仓库</p>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>之前的博客</title>
    <url>/2022/03/03/%E4%B9%8B%E5%89%8D%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/Recursions">https://blog.csdn.net/Recursions</a></p>
]]></content>
  </entry>
</search>
